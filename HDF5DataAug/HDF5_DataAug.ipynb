{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HDF5_DataAug.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM4dGDLyKLUzuybNwCTxx96"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"zYNBeF8d3WSO","colab_type":"code","colab":{}},"source":["import matplotlib\n","matplotlib.use(\"Agg\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oc4hvqGg3W-G","colab_type":"code","colab":{}},"source":["from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.optimizers import SGD\n","from keras.utils import np_utils\n","from imutils import paths\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import argparse\n","import cv2\n","import os\n","import h5py"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ydGVp4sU-8I","colab_type":"code","outputId":"b2474043-c66e-4f44-fd7d-37bf582ba9b3","executionInfo":{"status":"ok","timestamp":1585150535905,"user_tz":300,"elapsed":385,"user":{"displayName":"Vasanth Velayudham","photoUrl":"","userId":"10211271060426961523"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"p0XFRSBFUUug","colab_type":"code","colab":{}},"source":["hdf5_path = '/content/gdrive/My Drive/GoogleCollab/Notebooks/DataAugumentation/snapshots.hdf5'\n","dataset = h5py.File(hdf5_path, \"r\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oVsRZbdvWBWF","colab_type":"code","colab":{}},"source":["train_labels=np.array(dataset[\"train_labels\"])\n","train_labels = train_labels.reshape((len(train_labels),-1))\n","train_batch_labels=train_labels[train_batch_index]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bKZeBthsYY7w","colab_type":"code","colab":{}},"source":["train_batch_imgs=[]\n","for i in range(2500):\n","   img=(dataset['train_img'])[train_batch_index[i]]\n","   img=img/255.\n","   train_batch_imgs.append(img)    \n","train_batch_imgs=np.array(train_batch_imgs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-5ORCS3j3g0d","colab_type":"code","colab":{}},"source":["INIT_LR = 1e-1\n","BS = 8\n","EPOCHS = 50"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JiPsxH9q4CVe","colab_type":"code","colab":{}},"source":["data = train_batch_imgs\n","labels = train_batch_labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dtdXzBvWNUYv","colab_type":"code","outputId":"57c6cb2d-64c6-47b5-ee99-72150cb55ecc","executionInfo":{"status":"ok","timestamp":1585152054934,"user_tz":300,"elapsed":416,"user":{"displayName":"Vasanth Velayudham","photoUrl":"","userId":"10211271060426961523"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["le = LabelEncoder()\n","labels = le.fit_transform(labels)\n","labels = np_utils.to_categorical(labels, 2)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"PX336mc-NsCS","colab_type":"code","colab":{}},"source":["(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tlYN76kOOHMK","colab_type":"code","outputId":"e16c5be1-a714-4d40-a720-aabd6db633ab","executionInfo":{"status":"ok","timestamp":1585152062771,"user_tz":300,"elapsed":502,"user":{"displayName":"Vasanth Velayudham","photoUrl":"","userId":"10211271060426961523"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(\"[INFO] performing 'on the fly' data augmentation\")\n","aug = ImageDataGenerator(\n","\t\trotation_range=20,\n","\t\tzoom_range=0.15,\n","\t\twidth_shift_range=0.2,\n","\t\theight_shift_range=0.2,\n","\t\tshear_range=0.15,\n","\t\thorizontal_flip=True,\n","\t\tfill_mode=\"nearest\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[INFO] performing 'on the fly' data augmentation\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2Hrh4iSZPd74","colab_type":"code","colab":{}},"source":["from keras.layers.normalization import BatchNormalization\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import AveragePooling2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.layers.convolutional import ZeroPadding2D\n","from keras.layers.core import Activation\n","from keras.layers.core import Dense\n","from keras.layers import Flatten\n","from keras.layers import Input\n","from keras.models import Model\n","from keras.layers import add\n","from keras.regularizers import l2\n","from keras import backend as K\n","\n","class ResNet:\n","\t@staticmethod\n","\tdef residual_module(data, K, stride, chanDim, red=False,\n","\t\treg=0.0001, bnEps=2e-5, bnMom=0.9):\n","\t\t# the shortcut branch of the ResNet module should be\n","\t\t# initialize as the input (identity) data\n","\t\tshortcut = data\n","\n","\t\t# the first block of the ResNet module are the 1x1 CONVs\n","\t\tbn1 = BatchNormalization(axis=chanDim, epsilon=bnEps,\n","\t\t\tmomentum=bnMom)(data)\n","\t\tact1 = Activation(\"relu\")(bn1)\n","\t\tconv1 = Conv2D(int(K * 0.25), (1, 1), use_bias=False,\n","\t\t\tkernel_regularizer=l2(reg))(act1)\n","\n","\t\t# the second block of the ResNet module are the 3x3 CONVs\n","\t\tbn2 = BatchNormalization(axis=chanDim, epsilon=bnEps,\n","\t\t\tmomentum=bnMom)(conv1)\n","\t\tact2 = Activation(\"relu\")(bn2)\n","\t\tconv2 = Conv2D(int(K * 0.25), (3, 3), strides=stride,\n","\t\t\tpadding=\"same\", use_bias=False,\n","\t\t\tkernel_regularizer=l2(reg))(act2)\n","\n","\t\t# the third block of the ResNet module is another set of 1x1\n","\t\t# CONVs\n","\t\tbn3 = BatchNormalization(axis=chanDim, epsilon=bnEps,\n","\t\t\tmomentum=bnMom)(conv2)\n","\t\tact3 = Activation(\"relu\")(bn3)\n","\t\tconv3 = Conv2D(K, (1, 1), use_bias=False,\n","\t\t\tkernel_regularizer=l2(reg))(act3)\n","\n","\t\t# if we are to reduce the spatial size, apply a CONV layer to\n","\t\t# the shortcut\n","\t\tif red:\n","\t\t\tshortcut = Conv2D(K, (1, 1), strides=stride,\n","\t\t\t\tuse_bias=False, kernel_regularizer=l2(reg))(act1)\n","\n","\t\t# add together the shortcut and the final CONV\n","\t\tx = add([conv3, shortcut])\n","\n","\t\t# return the addition as the output of the ResNet module\n","\t\treturn x\n","\n","\t@staticmethod\n","\tdef build(width, height, depth, classes, stages, filters,\n","\t\treg=0.0001, bnEps=2e-5, bnMom=0.9):\n","\t\t# initialize the input shape to be \"channels last\" and the\n","\t\t# channels dimension itself\n","\t\tinputShape = (height, width, depth)\n","\t\tchanDim = -1\n","\n","\t\t# if we are using \"channels first\", update the input shape\n","\t\t# and channels dimension\n","\t\tif K.image_data_format() == \"channels_first\":\n","\t\t\tinputShape = (depth, height, width)\n","\t\t\tchanDim = 1\n","\n","\t\t# set the input and apply BN\n","\t\tinputs = Input(shape=inputShape)\n","\t\tx = BatchNormalization(axis=chanDim, epsilon=bnEps,\n","\t\t\tmomentum=bnMom)(inputs)\n","\n","\t\t# apply CONV => BN => ACT => POOL to reduce spatial size\n","\t\tx = Conv2D(filters[0], (5, 5), use_bias=False,\n","\t\t\tpadding=\"same\", kernel_regularizer=l2(reg))(x)\n","\t\tx = BatchNormalization(axis=chanDim, epsilon=bnEps,\n","\t\t\tmomentum=bnMom)(x)\n","\t\tx = Activation(\"relu\")(x)\n","\t\tx = ZeroPadding2D((1, 1))(x)\n","\t\tx = MaxPooling2D((3, 3), strides=(2, 2))(x)\n","\n","\t\t# loop over the number of stages\n","\t\tfor i in range(0, len(stages)):\n","\t\t\t# initialize the stride, then apply a residual module\n","\t\t\t# used to reduce the spatial size of the input volume\n","\t\t\tstride = (1, 1) if i == 0 else (2, 2)\n","\t\t\tx = ResNet.residual_module(x, filters[i + 1], stride,\n","\t\t\t\tchanDim, red=True, bnEps=bnEps, bnMom=bnMom)\n","\n","\t\t\t# loop over the number of layers in the stage\n","\t\t\tfor j in range(0, stages[i] - 1):\n","\t\t\t\t# apply a ResNet module\n","\t\t\t\tx = ResNet.residual_module(x, filters[i + 1],\n","\t\t\t\t\t(1, 1), chanDim, bnEps=bnEps, bnMom=bnMom)\n","\n","\t\t# apply BN => ACT => POOL\n","\t\tx = BatchNormalization(axis=chanDim, epsilon=bnEps,\n","\t\t\tmomentum=bnMom)(x)\n","\t\tx = Activation(\"relu\")(x)\n","\t\tx = AveragePooling2D((8, 8))(x)\n","\n","\t\t# softmax classifier\n","\t\tx = Flatten()(x)\n","\t\tx = Dense(classes, kernel_regularizer=l2(reg))(x)\n","\t\tx = Activation(\"softmax\")(x)\n","\n","\t\t# create the model\n","\t\tmodel = Model(inputs, x, name=\"resnet\")\n","\n","\t\t# return the constructed network architecture\n","\t\treturn model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xdHoyXb3OlPS","colab_type":"code","outputId":"dc80ab1e-a45e-4463-d127-275c90aef363","executionInfo":{"status":"ok","timestamp":1585152094206,"user_tz":300,"elapsed":3056,"user":{"displayName":"Vasanth Velayudham","photoUrl":"","userId":"10211271060426961523"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(\"[INFO] compiling model...\")\n","opt = SGD(lr=INIT_LR, momentum=0.9, decay=INIT_LR / EPOCHS)\n","model = ResNet.build(128, 128, 3, 2, (2, 3, 4),\n","\t(32, 64, 128, 256), reg=0.0001)\n","model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n","\tmetrics=[\"accuracy\"])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[INFO] compiling model...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZrCvcR_1OvL8","colab_type":"code","outputId":"e3018f60-459c-40a9-933f-b3db13bc428d","executionInfo":{"status":"ok","timestamp":1583524223653,"user_tz":360,"elapsed":2575303,"user":{"displayName":"Vasanth Velayudham","photoUrl":"","userId":"10211271060426961523"}},"colab":{"base_uri":"https://localhost:8080/","height":532}},"source":["print(\"[INFO] training network for {} epochs...\".format(EPOCHS))\n","H = model.fit_generator(\n","\taug.flow(trainX, trainY, batch_size=BS),\n","\tvalidation_data=(testX, testY),\n","\tsteps_per_epoch=len(trainX) // BS,\n","\tepochs=EPOCHS)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[INFO] training network for 50 epochs...\n","Epoch 1/50\n","234/234 [==============================] - 279s 1s/step - loss: 0.2225 - acc: 0.9957 - val_loss: 0.2114 - val_acc: 1.0000\n","Epoch 2/50\n","234/234 [==============================] - 275s 1s/step - loss: 0.2053 - acc: 1.0000 - val_loss: 0.1999 - val_acc: 1.0000\n","Epoch 3/50\n","234/234 [==============================] - 274s 1s/step - loss: 0.1954 - acc: 1.0000 - val_loss: 0.1913 - val_acc: 1.0000\n","Epoch 4/50\n","234/234 [==============================] - 274s 1s/step - loss: 0.1878 - acc: 1.0000 - val_loss: 0.1846 - val_acc: 1.0000\n","Epoch 5/50\n","234/234 [==============================] - 272s 1s/step - loss: 0.1817 - acc: 1.0000 - val_loss: 0.1791 - val_acc: 1.0000\n","Epoch 6/50\n","234/234 [==============================] - 270s 1s/step - loss: 0.1767 - acc: 1.0000 - val_loss: 0.1744 - val_acc: 1.0000\n","Epoch 7/50\n","234/234 [==============================] - 265s 1s/step - loss: 0.1724 - acc: 1.0000 - val_loss: 0.1704 - val_acc: 1.0000\n","Epoch 8/50\n","234/234 [==============================] - 270s 1s/step - loss: 0.1686 - acc: 1.0000 - val_loss: 0.1669 - val_acc: 1.0000\n","Epoch 9/50\n","234/234 [==============================] - 276s 1s/step - loss: 0.1653 - acc: 1.0000 - val_loss: 0.1637 - val_acc: 1.0000\n","Epoch 10/50\n","234/234 [==============================] - 278s 1s/step - loss: 0.1623 - acc: 1.0000 - val_loss: 0.1609 - val_acc: 1.0000\n","Epoch 11/50\n","234/234 [==============================] - 266s 1s/step - loss: 0.1597 - acc: 1.0000 - val_loss: 0.1584 - val_acc: 1.0000\n","Epoch 12/50\n","234/234 [==============================] - 275s 1s/step - loss: 0.1572 - acc: 1.0000 - val_loss: 0.1561 - val_acc: 1.0000\n","Epoch 13/50\n","234/234 [==============================] - 279s 1s/step - loss: 0.1550 - acc: 1.0000 - val_loss: 0.1540 - val_acc: 1.0000\n","Epoch 14/50\n","233/234 [============================>.] - ETA: 1s - loss: 0.1530 - acc: 1.0000"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kjQZJ1OTPs6N","colab_type":"code","outputId":"14d7396c-2395-4462-ccd4-050ced1b4125","executionInfo":{"status":"ok","timestamp":1583525493052,"user_tz":360,"elapsed":7644,"user":{"displayName":"Vasanth Velayudham","photoUrl":"","userId":"10211271060426961523"}},"colab":{"base_uri":"https://localhost:8080/","height":191}},"source":["print(\"[INFO] evaluating network...\")\n","predictions = model.predict(testX, batch_size=BS)\n","print(classification_report(testY.argmax(axis=1),\n","\tpredictions.argmax(axis=1), target_names=le.classes_))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[INFO] evaluating network...\n","              precision    recall  f1-score   support\n","\n","        cats       0.77      0.55      0.64       257\n","        dogs       0.64      0.83      0.72       243\n","\n","    accuracy                           0.69       500\n","   macro avg       0.70      0.69      0.68       500\n","weighted avg       0.71      0.69      0.68       500\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0ztC2OwZeVq4","colab_type":"code","colab":{}},"source":["N = np.arange(0, EPOCHS)\n","plt.style.use(\"ggplot\")\n","plt.figure()\n","plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n","plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n","plt.plot(N, H.history[\"acc\"], label=\"train_acc\")\n","plt.plot(N, H.history[\"val_acc\"], label=\"val_acc\")\n","plt.title(\"Training Loss and Accuracy on Dataset\")\n","plt.xlabel(\"Epoch #\")\n","plt.ylabel(\"Loss/Accuracy\")\n","plt.legend(loc=\"lower left\")\n","plt.savefig('/content/gdrive/My Drive/GoogleCollab/Notebooks/DataAugumentation/dogs_vs_cats_small/plot.jpg')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RDBJbGopebGP","colab_type":"code","outputId":"3a2a1918-c899-440b-a4b7-39219b01e2c7","executionInfo":{"status":"ok","timestamp":1583526028099,"user_tz":360,"elapsed":1305,"user":{"displayName":"Vasanth Velayudham","photoUrl":"","userId":"10211271060426961523"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["print(\"[INFO] loading example image...\")\n","from keras.preprocessing.image import load_img\n","from keras.preprocessing.image import img_to_array\n","image = load_img('/content/gdrive/My Drive/GoogleCollab/Notebooks/DataAugumentation/dogs_vs_cats_small/cats/cats_00001.jpg')\n","image = img_to_array(image)\n","image = np.expand_dims(image, axis=0)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[INFO] loading example image...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DLfrOnvAgD8b","colab_type":"code","colab":{}},"source":["aug = ImageDataGenerator(\n","\trotation_range=30,\n","\tzoom_range=0.15,\n","\twidth_shift_range=0.2,\n","\theight_shift_range=0.2,\n","\tshear_range=0.15,\n","\thorizontal_flip=True,\n","\tfill_mode=\"nearest\")\n","total = 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZlKEigPZg7av","colab_type":"code","outputId":"ff4a94c0-0de4-488e-e4f4-6350fa937805","executionInfo":{"status":"ok","timestamp":1583526503400,"user_tz":360,"elapsed":728,"user":{"displayName":"Vasanth Velayudham","photoUrl":"","userId":"10211271060426961523"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# construct the actual Python generator\n","print(\"[INFO] generating images...\")\n","imageGen = aug.flow(image, batch_size=1, save_to_dir='/content/gdrive/My Drive/GoogleCollab/Notebooks/DataAugumentation/dogs_vs_cats_small/output/',\n","\tsave_prefix=\"image\", save_format=\"jpg\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[INFO] generating images...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"axZtMrmahMfq","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}